{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text classification on the IMDB dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeSJSh8rc7yyV7RpdH3O8D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhugraj/Abstractive-summarizor/blob/master/text_classification_on_the_IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdd1TjYsiw4-"
      },
      "source": [
        "!pip install alibi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7CO37pfivI7",
        "outputId": "d782e004-95da-45bd-b10e-c3a6627416b5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from alibi.explainers import IntegratedGradients\n",
        "import matplotlib.pyplot as plt\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.6.2\n",
            "Eager execution enabled:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCvoCzZi8h0"
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMMpO3ANl4m8",
        "outputId": "c069bbf7-d41b-479c-ce39-60159b29aac4"
      },
      "source": [
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "test_labels = y_test.copy()\n",
        "train_labels = y_train.copy()\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "index = imdb.get_word_index()\n",
        "reverse_index = {value: key for (key, value) in index.items()}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS_7XeEDl7Yi"
      },
      "source": [
        "def decode_sentence(x, reverse_index):\n",
        "    # the `-3` offset is due to the special tokens used by keras\n",
        "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
        "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0cx2JxwmApr",
        "outputId": "b538ce60-ce0b-4419-9a30-ab60cd6c58c3"
      },
      "source": [
        "print(decode_sentence(x_test[5], reverse_index))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copies for everybody i know everything and everybody in this movie did a good job and i haven't figured out why disney hasn't put this movie on dvd or on vhs in rental stores at least i haven't seen any copies this is a wicked good movie and should be seen by all the kids in the new generation don't get to see it and i think they should it should at least be put back on the channel this movie doesn't deserve a cheap UNK it deserves the real thing i'm them now this movie will be on dvd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jyKPrH0mWOo"
      },
      "source": [
        "# Train Model\n",
        "\n",
        "The model includes one convolutional layer and reaches a test accuracy of 0.85. If save_model = True, a local folder ../model_imdb will be created and the trained model will be saved in that folder. If the model was previously saved, it can be loaded by setting load_model = True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWp1i6n7mD4z"
      },
      "source": [
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yoC-lejmf80"
      },
      "source": [
        "load_model = False\n",
        "save_model = True"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHzaWTYemirV",
        "outputId": "0b1c28c1-b1b6-4ac5-aca2-eaed58417d5d"
      },
      "source": [
        "filepath = './model_imdb/'  # change to directory where model is downloaded\n",
        "if load_model:\n",
        "    model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))\n",
        "else:\n",
        "    print('Build model...')\n",
        "\n",
        "    inputs = Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedded_sequences = Embedding(max_features,\n",
        "                                   embedding_dims)(inputs)\n",
        "    out = Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1)(embedded_sequences)\n",
        "    out = Dropout(0.4)(out)\n",
        "    out = GlobalMaxPooling1D()(out)\n",
        "    out = Dense(hidden_dims,\n",
        "                activation='relu')(out)\n",
        "    out = Dropout(0.4)(out)\n",
        "    outputs = Dense(2, activation='softmax')(out)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Train...')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=256,\n",
        "              epochs=3,\n",
        "              validation_data=(x_test, y_test))\n",
        "    if save_model:\n",
        "        if not os.path.exists(filepath):\n",
        "            os.makedirs(filepath)\n",
        "        model.save(os.path.join(filepath, 'model.h5'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Train...\n",
            "Epoch 1/3\n",
            "98/98 [==============================] - 27s 269ms/step - loss: 0.5969 - accuracy: 0.6586 - val_loss: 0.4227 - val_accuracy: 0.8145\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 26s 267ms/step - loss: 0.3223 - accuracy: 0.8629 - val_loss: 0.3477 - val_accuracy: 0.8537\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 26s 268ms/step - loss: 0.2131 - accuracy: 0.9181 - val_loss: 0.3357 - val_accuracy: 0.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9yL_EksngEi"
      },
      "source": [
        "# Calculate integrated gradients\n",
        "\n",
        "The integrated gradients attributions are calculated with respect to the embedding layer for 10 samples from the test set. Since the model uses a word to vector embedding with vector dimensionality of 50 and sequence length of 100 words, the dimensionality of the attributions is (10, 100, 50). In order to obtain a single attribution value for each word, we sum all the attribution values for the 50 elements of each word’s vector representation.\n",
        "\n",
        "The default baseline is used in this example which is internally defined as a sequence of zeros. In this case, this corresponds to a sequence of padding characters (NB: in general the numerical value corresponding to a “non-informative” baseline such as the PAD token will depend on the tokenizer used, make sure that the numerical value of the baseline used corresponds to your desired token value to avoid surprises). The path integral is defined as a straight line from the baseline to the input image. The path is approximated by choosing 50 discrete steps according to the Gauss-Legendre method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVNu6tc8mrEM",
        "outputId": "f04c98f6-3e06-4c4b-edec-c991d9be9da1"
      },
      "source": [
        "layer = model.layers[1]\n",
        "layer"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7ff35e94ed10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzfZasyEnvka"
      },
      "source": [
        "n_steps = 50\n",
        "method = \"gausslegendre\"\n",
        "internal_batch_size = 100\n",
        "nb_samples = 10\n",
        "ig  = IntegratedGradients(model,\n",
        "                          layer=layer,\n",
        "                          n_steps=n_steps,\n",
        "                          method=method,\n",
        "                          internal_batch_size=internal_batch_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlEXxCginy9L"
      },
      "source": [
        "x_test_sample = x_test[:nb_samples]\n",
        "predictions = model(x_test_sample).numpy().argmax(axis=1)\n",
        "explanation = ig.explain(x_test_sample,\n",
        "                         baselines=None,\n",
        "                         target=predictions,\n",
        "                         attribute_to_layer_inputs=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb-40hhxn2Rj",
        "outputId": "ba446fdc-79f6-492e-804f-b0da8df007a2"
      },
      "source": [
        "# Metadata from the explanation object\n",
        "explanation.meta"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'explanations': ['local'],\n",
              " 'name': 'IntegratedGradients',\n",
              " 'params': {'internal_batch_size': 100,\n",
              "  'layer': 1,\n",
              "  'method': 'gausslegendre',\n",
              "  'n_steps': 50},\n",
              " 'type': ['whitebox'],\n",
              " 'version': '0.6.2'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81_pUCVNn4gD",
        "outputId": "a3b358bb-ed5f-4aab-f0bb-142b8c6c12b8"
      },
      "source": [
        "# Data fields from the explanation object\n",
        "explanation.data.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['attributions', 'X', 'forward_kwargs', 'baselines', 'predictions', 'deltas', 'target'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0aPUgoqn-Jq",
        "outputId": "43a66829-2720-4d68-9494-da7defa9501c"
      },
      "source": [
        "# Get attributions values from the explanation object\n",
        "attrs = explanation.attributions[0]\n",
        "print('Attributions shape:', attrs.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attributions shape: (10, 100, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4A-4WIoBW7",
        "outputId": "1dc2d5f7-c113-49ac-d4c1-a611cfee3af0"
      },
      "source": [
        "attrs = attrs.sum(axis=2)\n",
        "print('Attributions shape:', attrs.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attributions shape: (10, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yzcl8zmoIDZ"
      },
      "source": [
        "# Visualize attributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URGLusBOoFWz",
        "outputId": "1a5fdedc-4315-4c3c-9fc7-88a4d1a7405a"
      },
      "source": [
        "i = 5\n",
        "x_i = x_test_sample[i]\n",
        "attrs_i = attrs[i]\n",
        "pred = predictions[i]\n",
        "pred_dict = {1: 'Positive review', 0: 'Negative review'}\n",
        "\n",
        "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label =  1: Positive review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luqggl8boOh8"
      },
      "source": [
        "from IPython.display import HTML\n",
        "def  hlstr(string, color='white'):\n",
        "    \"\"\"\n",
        "    Return HTML markup highlighting text with the desired color.\n",
        "    \"\"\"\n",
        "    return f\"<mark style=background-color:{color}>{string} </mark>\"\n",
        "\n",
        "def colorize(attrs, cmap='PiYG'):\n",
        "    \"\"\"\n",
        "    Compute hex colors based on the attributions for a single instance.\n",
        "    Uses a diverging colorscale by default and normalizes and scales\n",
        "    the colormap so that colors are consistent with the attributions.\n",
        "    \"\"\"\n",
        "    import matplotlib as mpl\n",
        "    cmap_bound = np.abs(attrs).max()\n",
        "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
        "    cmap = mpl.cm.get_cmap(cmap)\n",
        "\n",
        "    # now compute hex values of colors\n",
        "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
        "    return colors"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm_wCmV5ohir"
      },
      "source": [
        "Below we visualize the attribution values (highlighted in the text) having the highest positive attributions. Words with  **high positive attribution are \n",
        "highlighted in shades of green** and words with ***negative attribution in shades of pink***. Stronger shading corresponds to higher attribution values. Positive attributions can be interpreted as increase in probability of the predicted class (“Positive sentiment”) while negative attributions correspond to decrease in probability of the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktWSTS4vodwr"
      },
      "source": [
        "words = decode_sentence(x_i, reverse_index).split()\n",
        "colors = colorize(attrs_i)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ndj2rmueolIL",
        "outputId": "da58c97a-791c-418b-892c-02eaf6b67417"
      },
      "source": [
        "HTML(\"\".join(list(map(hlstr, words, colors))))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<mark style=background-color:#f7f7f6>copies </mark><mark style=background-color:#f7f7f6>for </mark><mark style=background-color:#f7f7f6>everybody </mark><mark style=background-color:#f7f7f6>i </mark><mark style=background-color:#f7f7f6>know </mark><mark style=background-color:#f7f7f6>everything </mark><mark style=background-color:#f7f7f6>and </mark><mark style=background-color:#f8f4f6>everybody </mark><mark style=background-color:#f8f5f6>in </mark><mark style=background-color:#faecf3>this </mark><mark style=background-color:#f7f7f6>movie </mark><mark style=background-color:#f9f0f5>did </mark><mark style=background-color:#e9f5d8>a </mark><mark style=background-color:#77b53c>good </mark><mark style=background-color:#2d6b1a>job </mark><mark style=background-color:#8ac34f>and </mark><mark style=background-color:#f6f7f5>i </mark><mark style=background-color:#e7f5d2>haven't </mark><mark style=background-color:#8e0152>figured </mark><mark style=background-color:#ea9fca>out </mark><mark style=background-color:#e07eb3>why </mark><mark style=background-color:#f6f7f5>disney </mark><mark style=background-color:#f8f3f6>hasn't </mark><mark style=background-color:#f6f7f5>put </mark><mark style=background-color:#f8f3f6>this </mark><mark style=background-color:#f3f7ef>movie </mark><mark style=background-color:#f3f7ef>on </mark><mark style=background-color:#bbe28a>dvd </mark><mark style=background-color:#edf6df>or </mark><mark style=background-color:#f7f7f6>on </mark><mark style=background-color:#b5df82>vhs </mark><mark style=background-color:#f7f7f7>in </mark><mark style=background-color:#fbd8eb>rental </mark><mark style=background-color:#f5f7f3>stores </mark><mark style=background-color:#f9f1f5>at </mark><mark style=background-color:#f9f0f5>least </mark><mark style=background-color:#f0f6e7>i </mark><mark style=background-color:#7bb93e>haven't </mark><mark style=background-color:#c4e699>seen </mark><mark style=background-color:#f3bcdd>any </mark><mark style=background-color:#eaf5d9>copies </mark><mark style=background-color:#fce5f1>this </mark><mark style=background-color:#62a32e>is </mark><mark style=background-color:#589b28>a </mark><mark style=background-color:#a9d874>wicked </mark><mark style=background-color:#edf6e1>good </mark><mark style=background-color:#f3f6ed>movie </mark><mark style=background-color:#f3f7ef>and </mark><mark style=background-color:#f3f7ef>should </mark><mark style=background-color:#f6f7f5>be </mark><mark style=background-color:#e9f5d8>seen </mark><mark style=background-color:#f3f7ef>by </mark><mark style=background-color:#f1f6ea>all </mark><mark style=background-color:#f7f7f6>the </mark><mark style=background-color:#f7f7f6>kids </mark><mark style=background-color:#f7f7f6>in </mark><mark style=background-color:#f1f6ea>the </mark><mark style=background-color:#f7f7f7>new </mark><mark style=background-color:#f4f7f0>generation </mark><mark style=background-color:#f8f3f6>don't </mark><mark style=background-color:#f6f7f5>get </mark><mark style=background-color:#f8f4f6>to </mark><mark style=background-color:#d8efb9>see </mark><mark style=background-color:#b2dd7f>it </mark><mark style=background-color:#d2ecb0>and </mark><mark style=background-color:#f3f7ef>i </mark><mark style=background-color:#f4f7f0>think </mark><mark style=background-color:#f9eef4>they </mark><mark style=background-color:#f5f7f2>should </mark><mark style=background-color:#f3f6ed>it </mark><mark style=background-color:#f5f7f2>should </mark><mark style=background-color:#fde2f0>at </mark><mark style=background-color:#fbd9ec>least </mark><mark style=background-color:#f8f5f6>be </mark><mark style=background-color:#f7f7f6>put </mark><mark style=background-color:#f7f7f6>back </mark><mark style=background-color:#f7f7f6>on </mark><mark style=background-color:#f7f7f7>the </mark><mark style=background-color:#faeaf2>channel </mark><mark style=background-color:#f9d1e8>this </mark><mark style=background-color:#f7f6f7>movie </mark><mark style=background-color:#aa0e68>doesn't </mark><mark style=background-color:#b51370>deserve </mark><mark style=background-color:#f2b8db>a </mark><mark style=background-color:#c01879>cheap </mark><mark style=background-color:#fde1ef>UNK </mark><mark style=background-color:#edf6df>it </mark><mark style=background-color:#e7f5d2>deserves </mark><mark style=background-color:#f3f6ed>the </mark><mark style=background-color:#f3f6ed>real </mark><mark style=background-color:#f7cbe4>thing </mark><mark style=background-color:#eeabd2>i'm </mark><mark style=background-color:#f8f4f6>them </mark><mark style=background-color:#cfebaa>now </mark><mark style=background-color:#f5f7f2>this </mark><mark style=background-color:#eff6e5>movie </mark><mark style=background-color:#f7f7f6>will </mark><mark style=background-color:#f7f7f6>be </mark><mark style=background-color:#f7f7f6>on </mark><mark style=background-color:#f6f7f5>dvd </mark>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jc0tnUiooqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}