{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adv_Bias_inProcess.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOvHa2j9H7tHVpYlw+bGVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhugraj/Abstractive-summarizor/blob/master/Adv_Bias_inProcess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aif360\n",
        "!pip install fairlearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3KxW-4Ju7CC",
        "outputId": "aa112848-473b-4370-929b-e1e6bc95fa4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n",
            "Collecting tempeh\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (3.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n",
            "Collecting shap\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n",
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.59.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.3)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.59.0-py3-none-any.whl size=31313 sha256=b7951a76532f1b7b9fc2dd506613727337212f1063c7c26e487172bd3cbbcf7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/6e/d2/af9dae73f8fef0c64c18b0a02a69fbd4c65b854912fa87a390\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n",
            "Successfully installed aif360-0.4.0 memory-profiler-0.59.0 shap-0.40.0 slicer-0.0.7 tempeh-0.1.12\n",
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.1.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l-Zciytso1rm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sys\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
        "\n",
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_orig = load_preproc_data_adult()\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
      ],
      "metadata": {
        "id": "kXU2RT2Su9u6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(\"#### Training Dataset shape\"))\n",
        "print(dataset_orig_train.features.shape)\n",
        "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "display(Markdown(\"#### Protected attribute names\"))\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "display(Markdown(\"#### Dataset feature names\"))\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "mAT360Bg1tff",
        "outputId": "ad149a85-5fee-461d-85fc-8266676ecb55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Training Dataset shape",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34189, 18)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Favorable and unfavorable labels",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Protected attribute names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sex', 'race']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Privileged and unprivileged protected attribute values",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Dataset feature names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric for the original dataset\n",
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
        "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "8ncs5N0AxDj1",
        "outputId": "ab0e2490-2e8d-44ee-94b8-f5919245961a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Original training dataset",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.196835\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.189073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaler = MaxAbsScaler()\n",
        "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
        "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
        "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "KAFZOgSZxIhI",
        "outputId": "8071b59e-a946-4c53-c563-8e8ebe608c8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Scaled dataset - Verify that the scaling does not affect the group label statistics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.196835\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.189073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load post-processing algorithm that equalizes the odds\n",
        "# Learn parameters with debias set to False\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "sess = tf.Session()\n",
        "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='plain_classifier',\n",
        "                          debias=False,\n",
        "                          sess=sess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CUBDS9fxMeJ",
        "outputId": "4c99a355-2742-48e1-e84b-3cc7c34a6e03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plain_model.fit(dataset_orig_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRIrbsrIxUW3",
        "outputId": "08dc32bb-1875-4f39-c9a2-3dd72500db42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "epoch 0; iter: 0; batch classifier loss: 0.695702\n",
            "epoch 0; iter: 200; batch classifier loss: 0.411451\n",
            "epoch 1; iter: 0; batch classifier loss: 0.432642\n",
            "epoch 1; iter: 200; batch classifier loss: 0.478360\n",
            "epoch 2; iter: 0; batch classifier loss: 0.402665\n",
            "epoch 2; iter: 200; batch classifier loss: 0.420036\n",
            "epoch 3; iter: 0; batch classifier loss: 0.425418\n",
            "epoch 3; iter: 200; batch classifier loss: 0.425617\n",
            "epoch 4; iter: 0; batch classifier loss: 0.427238\n",
            "epoch 4; iter: 200; batch classifier loss: 0.336292\n",
            "epoch 5; iter: 0; batch classifier loss: 0.472720\n",
            "epoch 5; iter: 200; batch classifier loss: 0.377967\n",
            "epoch 6; iter: 0; batch classifier loss: 0.507377\n",
            "epoch 6; iter: 200; batch classifier loss: 0.382774\n",
            "epoch 7; iter: 0; batch classifier loss: 0.333773\n",
            "epoch 7; iter: 200; batch classifier loss: 0.440061\n",
            "epoch 8; iter: 0; batch classifier loss: 0.392806\n",
            "epoch 8; iter: 200; batch classifier loss: 0.499404\n",
            "epoch 9; iter: 0; batch classifier loss: 0.465530\n",
            "epoch 9; iter: 200; batch classifier loss: 0.391972\n",
            "epoch 10; iter: 0; batch classifier loss: 0.386722\n",
            "epoch 10; iter: 200; batch classifier loss: 0.374521\n",
            "epoch 11; iter: 0; batch classifier loss: 0.457189\n",
            "epoch 11; iter: 200; batch classifier loss: 0.395302\n",
            "epoch 12; iter: 0; batch classifier loss: 0.456786\n",
            "epoch 12; iter: 200; batch classifier loss: 0.380061\n",
            "epoch 13; iter: 0; batch classifier loss: 0.553142\n",
            "epoch 13; iter: 200; batch classifier loss: 0.450228\n",
            "epoch 14; iter: 0; batch classifier loss: 0.433778\n",
            "epoch 14; iter: 200; batch classifier loss: 0.423791\n",
            "epoch 15; iter: 0; batch classifier loss: 0.318954\n",
            "epoch 15; iter: 200; batch classifier loss: 0.418055\n",
            "epoch 16; iter: 0; batch classifier loss: 0.510040\n",
            "epoch 16; iter: 200; batch classifier loss: 0.403660\n",
            "epoch 17; iter: 0; batch classifier loss: 0.449560\n",
            "epoch 17; iter: 200; batch classifier loss: 0.454818\n",
            "epoch 18; iter: 0; batch classifier loss: 0.323765\n",
            "epoch 18; iter: 200; batch classifier loss: 0.528357\n",
            "epoch 19; iter: 0; batch classifier loss: 0.395824\n",
            "epoch 19; iter: 200; batch classifier loss: 0.472510\n",
            "epoch 20; iter: 0; batch classifier loss: 0.425804\n",
            "epoch 20; iter: 200; batch classifier loss: 0.381865\n",
            "epoch 21; iter: 0; batch classifier loss: 0.461665\n",
            "epoch 21; iter: 200; batch classifier loss: 0.411101\n",
            "epoch 22; iter: 0; batch classifier loss: 0.322128\n",
            "epoch 22; iter: 200; batch classifier loss: 0.486004\n",
            "epoch 23; iter: 0; batch classifier loss: 0.362016\n",
            "epoch 23; iter: 200; batch classifier loss: 0.401144\n",
            "epoch 24; iter: 0; batch classifier loss: 0.426761\n",
            "epoch 24; iter: 200; batch classifier loss: 0.446590\n",
            "epoch 25; iter: 0; batch classifier loss: 0.446910\n",
            "epoch 25; iter: 200; batch classifier loss: 0.515744\n",
            "epoch 26; iter: 0; batch classifier loss: 0.413218\n",
            "epoch 26; iter: 200; batch classifier loss: 0.416531\n",
            "epoch 27; iter: 0; batch classifier loss: 0.421162\n",
            "epoch 27; iter: 200; batch classifier loss: 0.449496\n",
            "epoch 28; iter: 0; batch classifier loss: 0.423272\n",
            "epoch 28; iter: 200; batch classifier loss: 0.476294\n",
            "epoch 29; iter: 0; batch classifier loss: 0.440538\n",
            "epoch 29; iter: 200; batch classifier loss: 0.406385\n",
            "epoch 30; iter: 0; batch classifier loss: 0.460296\n",
            "epoch 30; iter: 200; batch classifier loss: 0.431637\n",
            "epoch 31; iter: 0; batch classifier loss: 0.525348\n",
            "epoch 31; iter: 200; batch classifier loss: 0.420572\n",
            "epoch 32; iter: 0; batch classifier loss: 0.394601\n",
            "epoch 32; iter: 200; batch classifier loss: 0.406759\n",
            "epoch 33; iter: 0; batch classifier loss: 0.418455\n",
            "epoch 33; iter: 200; batch classifier loss: 0.401545\n",
            "epoch 34; iter: 0; batch classifier loss: 0.431910\n",
            "epoch 34; iter: 200; batch classifier loss: 0.533258\n",
            "epoch 35; iter: 0; batch classifier loss: 0.412516\n",
            "epoch 35; iter: 200; batch classifier loss: 0.400269\n",
            "epoch 36; iter: 0; batch classifier loss: 0.433262\n",
            "epoch 36; iter: 200; batch classifier loss: 0.441265\n",
            "epoch 37; iter: 0; batch classifier loss: 0.393015\n",
            "epoch 37; iter: 200; batch classifier loss: 0.360224\n",
            "epoch 38; iter: 0; batch classifier loss: 0.379604\n",
            "epoch 38; iter: 200; batch classifier loss: 0.408616\n",
            "epoch 39; iter: 0; batch classifier loss: 0.360806\n",
            "epoch 39; iter: 200; batch classifier loss: 0.441830\n",
            "epoch 40; iter: 0; batch classifier loss: 0.366220\n",
            "epoch 40; iter: 200; batch classifier loss: 0.506154\n",
            "epoch 41; iter: 0; batch classifier loss: 0.379696\n",
            "epoch 41; iter: 200; batch classifier loss: 0.388765\n",
            "epoch 42; iter: 0; batch classifier loss: 0.447908\n",
            "epoch 42; iter: 200; batch classifier loss: 0.389908\n",
            "epoch 43; iter: 0; batch classifier loss: 0.461674\n",
            "epoch 43; iter: 200; batch classifier loss: 0.424277\n",
            "epoch 44; iter: 0; batch classifier loss: 0.452314\n",
            "epoch 44; iter: 200; batch classifier loss: 0.479053\n",
            "epoch 45; iter: 0; batch classifier loss: 0.395799\n",
            "epoch 45; iter: 200; batch classifier loss: 0.480088\n",
            "epoch 46; iter: 0; batch classifier loss: 0.510037\n",
            "epoch 46; iter: 200; batch classifier loss: 0.348275\n",
            "epoch 47; iter: 0; batch classifier loss: 0.421208\n",
            "epoch 47; iter: 200; batch classifier loss: 0.460041\n",
            "epoch 48; iter: 0; batch classifier loss: 0.467943\n",
            "epoch 48; iter: 200; batch classifier loss: 0.396527\n",
            "epoch 49; iter: 0; batch classifier loss: 0.406192\n",
            "epoch 49; iter: 200; batch classifier loss: 0.428152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fb220f97fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
        "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
      ],
      "metadata": {
        "id": "BU46CSHuyb85"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_nodebiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "vLgH7kofyoBU",
        "outputId": "80da2391-1af5-4fee-c5fa-5ecae7fd66e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.210607\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.218465\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.806183\n",
            "Test set: Balanced classification accuracy = 0.664527\n",
            "Test set: Disparate impact = 0.000000\n",
            "Test set: Equal opportunity difference = -0.470103\n",
            "Test set: Average odds difference = -0.290826\n",
            "Test set: Theil_index = 0.173192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "metadata": {
        "id": "RXMKI9RXysnH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn parameters with debias set to True\n",
        "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='debiased_classifier',\n",
        "                          debias=True,\n",
        "                          sess=sess)"
      ],
      "metadata": {
        "id": "UlO201-2yzGd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debiased_model.fit(dataset_orig_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_ALLO2qy1uJ",
        "outputId": "7d4e6fe9-37a3-4b0f-abc2-ca2aa5687e7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.692086; batch adversarial loss: 0.667461\n",
            "epoch 0; iter: 200; batch classifier loss: 0.492503; batch adversarial loss: 0.690601\n",
            "epoch 1; iter: 0; batch classifier loss: 0.569376; batch adversarial loss: 0.757484\n",
            "epoch 1; iter: 200; batch classifier loss: 0.578737; batch adversarial loss: 0.664236\n",
            "epoch 2; iter: 0; batch classifier loss: 0.698937; batch adversarial loss: 0.684701\n",
            "epoch 2; iter: 200; batch classifier loss: 0.694900; batch adversarial loss: 0.641905\n",
            "epoch 3; iter: 0; batch classifier loss: 0.527155; batch adversarial loss: 0.672923\n",
            "epoch 3; iter: 200; batch classifier loss: 0.358030; batch adversarial loss: 0.678453\n",
            "epoch 4; iter: 0; batch classifier loss: 0.483289; batch adversarial loss: 0.582703\n",
            "epoch 4; iter: 200; batch classifier loss: 0.413672; batch adversarial loss: 0.536004\n",
            "epoch 5; iter: 0; batch classifier loss: 0.471024; batch adversarial loss: 0.591549\n",
            "epoch 5; iter: 200; batch classifier loss: 0.502687; batch adversarial loss: 0.605772\n",
            "epoch 6; iter: 0; batch classifier loss: 0.326734; batch adversarial loss: 0.613760\n",
            "epoch 6; iter: 200; batch classifier loss: 0.413443; batch adversarial loss: 0.600311\n",
            "epoch 7; iter: 0; batch classifier loss: 0.445081; batch adversarial loss: 0.592705\n",
            "epoch 7; iter: 200; batch classifier loss: 0.440395; batch adversarial loss: 0.625470\n",
            "epoch 8; iter: 0; batch classifier loss: 0.390978; batch adversarial loss: 0.613866\n",
            "epoch 8; iter: 200; batch classifier loss: 0.393459; batch adversarial loss: 0.600160\n",
            "epoch 9; iter: 0; batch classifier loss: 0.375139; batch adversarial loss: 0.608680\n",
            "epoch 9; iter: 200; batch classifier loss: 0.453146; batch adversarial loss: 0.637592\n",
            "epoch 10; iter: 0; batch classifier loss: 0.449750; batch adversarial loss: 0.631718\n",
            "epoch 10; iter: 200; batch classifier loss: 0.412206; batch adversarial loss: 0.612251\n",
            "epoch 11; iter: 0; batch classifier loss: 0.429811; batch adversarial loss: 0.588318\n",
            "epoch 11; iter: 200; batch classifier loss: 0.543626; batch adversarial loss: 0.568735\n",
            "epoch 12; iter: 0; batch classifier loss: 0.411319; batch adversarial loss: 0.582957\n",
            "epoch 12; iter: 200; batch classifier loss: 0.404976; batch adversarial loss: 0.589670\n",
            "epoch 13; iter: 0; batch classifier loss: 0.372783; batch adversarial loss: 0.589497\n",
            "epoch 13; iter: 200; batch classifier loss: 0.415777; batch adversarial loss: 0.667366\n",
            "epoch 14; iter: 0; batch classifier loss: 0.393328; batch adversarial loss: 0.613480\n",
            "epoch 14; iter: 200; batch classifier loss: 0.455988; batch adversarial loss: 0.565743\n",
            "epoch 15; iter: 0; batch classifier loss: 0.452336; batch adversarial loss: 0.584476\n",
            "epoch 15; iter: 200; batch classifier loss: 0.482058; batch adversarial loss: 0.629492\n",
            "epoch 16; iter: 0; batch classifier loss: 0.481406; batch adversarial loss: 0.647364\n",
            "epoch 16; iter: 200; batch classifier loss: 0.450979; batch adversarial loss: 0.587950\n",
            "epoch 17; iter: 0; batch classifier loss: 0.368519; batch adversarial loss: 0.658898\n",
            "epoch 17; iter: 200; batch classifier loss: 0.441371; batch adversarial loss: 0.670105\n",
            "epoch 18; iter: 0; batch classifier loss: 0.448929; batch adversarial loss: 0.595729\n",
            "epoch 18; iter: 200; batch classifier loss: 0.451041; batch adversarial loss: 0.622430\n",
            "epoch 19; iter: 0; batch classifier loss: 0.471737; batch adversarial loss: 0.601709\n",
            "epoch 19; iter: 200; batch classifier loss: 0.364780; batch adversarial loss: 0.596169\n",
            "epoch 20; iter: 0; batch classifier loss: 0.421111; batch adversarial loss: 0.595044\n",
            "epoch 20; iter: 200; batch classifier loss: 0.379926; batch adversarial loss: 0.667057\n",
            "epoch 21; iter: 0; batch classifier loss: 0.401129; batch adversarial loss: 0.561881\n",
            "epoch 21; iter: 200; batch classifier loss: 0.527822; batch adversarial loss: 0.604598\n",
            "epoch 22; iter: 0; batch classifier loss: 0.426617; batch adversarial loss: 0.582141\n",
            "epoch 22; iter: 200; batch classifier loss: 0.446803; batch adversarial loss: 0.588078\n",
            "epoch 23; iter: 0; batch classifier loss: 0.562458; batch adversarial loss: 0.578822\n",
            "epoch 23; iter: 200; batch classifier loss: 0.382335; batch adversarial loss: 0.598511\n",
            "epoch 24; iter: 0; batch classifier loss: 0.361021; batch adversarial loss: 0.558896\n",
            "epoch 24; iter: 200; batch classifier loss: 0.365960; batch adversarial loss: 0.670780\n",
            "epoch 25; iter: 0; batch classifier loss: 0.390040; batch adversarial loss: 0.583398\n",
            "epoch 25; iter: 200; batch classifier loss: 0.445272; batch adversarial loss: 0.596087\n",
            "epoch 26; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.577106\n",
            "epoch 26; iter: 200; batch classifier loss: 0.451420; batch adversarial loss: 0.591622\n",
            "epoch 27; iter: 0; batch classifier loss: 0.387278; batch adversarial loss: 0.653637\n",
            "epoch 27; iter: 200; batch classifier loss: 0.418673; batch adversarial loss: 0.604304\n",
            "epoch 28; iter: 0; batch classifier loss: 0.455598; batch adversarial loss: 0.612535\n",
            "epoch 28; iter: 200; batch classifier loss: 0.468294; batch adversarial loss: 0.657885\n",
            "epoch 29; iter: 0; batch classifier loss: 0.434981; batch adversarial loss: 0.596362\n",
            "epoch 29; iter: 200; batch classifier loss: 0.394205; batch adversarial loss: 0.604474\n",
            "epoch 30; iter: 0; batch classifier loss: 0.490872; batch adversarial loss: 0.575625\n",
            "epoch 30; iter: 200; batch classifier loss: 0.408563; batch adversarial loss: 0.600952\n",
            "epoch 31; iter: 0; batch classifier loss: 0.370647; batch adversarial loss: 0.580458\n",
            "epoch 31; iter: 200; batch classifier loss: 0.373720; batch adversarial loss: 0.611206\n",
            "epoch 32; iter: 0; batch classifier loss: 0.395947; batch adversarial loss: 0.577974\n",
            "epoch 32; iter: 200; batch classifier loss: 0.432439; batch adversarial loss: 0.575262\n",
            "epoch 33; iter: 0; batch classifier loss: 0.430501; batch adversarial loss: 0.593317\n",
            "epoch 33; iter: 200; batch classifier loss: 0.364084; batch adversarial loss: 0.544840\n",
            "epoch 34; iter: 0; batch classifier loss: 0.461244; batch adversarial loss: 0.604206\n",
            "epoch 34; iter: 200; batch classifier loss: 0.431007; batch adversarial loss: 0.637705\n",
            "epoch 35; iter: 0; batch classifier loss: 0.399978; batch adversarial loss: 0.607596\n",
            "epoch 35; iter: 200; batch classifier loss: 0.394909; batch adversarial loss: 0.570982\n",
            "epoch 36; iter: 0; batch classifier loss: 0.494588; batch adversarial loss: 0.620055\n",
            "epoch 36; iter: 200; batch classifier loss: 0.468206; batch adversarial loss: 0.644857\n",
            "epoch 37; iter: 0; batch classifier loss: 0.455844; batch adversarial loss: 0.614076\n",
            "epoch 37; iter: 200; batch classifier loss: 0.502767; batch adversarial loss: 0.662810\n",
            "epoch 38; iter: 0; batch classifier loss: 0.421999; batch adversarial loss: 0.623539\n",
            "epoch 38; iter: 200; batch classifier loss: 0.478065; batch adversarial loss: 0.637311\n",
            "epoch 39; iter: 0; batch classifier loss: 0.479105; batch adversarial loss: 0.590060\n",
            "epoch 39; iter: 200; batch classifier loss: 0.442933; batch adversarial loss: 0.633032\n",
            "epoch 40; iter: 0; batch classifier loss: 0.459272; batch adversarial loss: 0.589936\n",
            "epoch 40; iter: 200; batch classifier loss: 0.424914; batch adversarial loss: 0.574584\n",
            "epoch 41; iter: 0; batch classifier loss: 0.428875; batch adversarial loss: 0.585181\n",
            "epoch 41; iter: 200; batch classifier loss: 0.400024; batch adversarial loss: 0.565833\n",
            "epoch 42; iter: 0; batch classifier loss: 0.397662; batch adversarial loss: 0.525921\n",
            "epoch 42; iter: 200; batch classifier loss: 0.388930; batch adversarial loss: 0.580495\n",
            "epoch 43; iter: 0; batch classifier loss: 0.352849; batch adversarial loss: 0.577460\n",
            "epoch 43; iter: 200; batch classifier loss: 0.427749; batch adversarial loss: 0.590588\n",
            "epoch 44; iter: 0; batch classifier loss: 0.456338; batch adversarial loss: 0.596602\n",
            "epoch 44; iter: 200; batch classifier loss: 0.396707; batch adversarial loss: 0.609805\n",
            "epoch 45; iter: 0; batch classifier loss: 0.491478; batch adversarial loss: 0.658976\n",
            "epoch 45; iter: 200; batch classifier loss: 0.476271; batch adversarial loss: 0.603456\n",
            "epoch 46; iter: 0; batch classifier loss: 0.393627; batch adversarial loss: 0.566168\n",
            "epoch 46; iter: 200; batch classifier loss: 0.362483; batch adversarial loss: 0.625688\n",
            "epoch 47; iter: 0; batch classifier loss: 0.429128; batch adversarial loss: 0.601329\n",
            "epoch 47; iter: 200; batch classifier loss: 0.373609; batch adversarial loss: 0.626750\n",
            "epoch 48; iter: 0; batch classifier loss: 0.502467; batch adversarial loss: 0.581128\n",
            "epoch 48; iter: 200; batch classifier loss: 0.418154; batch adversarial loss: 0.623618\n",
            "epoch 49; iter: 0; batch classifier loss: 0.394792; batch adversarial loss: 0.609329\n",
            "epoch 49; iter: 200; batch classifier loss: 0.517650; batch adversarial loss: 0.593005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fb21bd6bbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
      ],
      "metadata": {
        "id": "6GPMxkd0y4e1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "# Metrics for the dataset from model with debiasing\n",
        "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
        "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
        "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "YV11R-qYzFcS",
        "outputId": "a3394dfa-9eb5-405e-ca8d-25cb057040de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.210607\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.218465\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Model - with debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.085963\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.086035\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.806183\n",
            "Test set: Balanced classification accuracy = 0.664527\n",
            "Test set: Disparate impact = 0.000000\n",
            "Test set: Equal opportunity difference = -0.470103\n",
            "Test set: Average odds difference = -0.290826\n",
            "Test set: Theil_index = 0.173192\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Model - with debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.794308\n",
            "Test set: Balanced classification accuracy = 0.674868\n",
            "Test set: Disparate impact = 0.591627\n",
            "Test set: Equal opportunity difference = -0.053238\n",
            "Test set: Average odds difference = -0.034290\n",
            "Test set: Theil_index = 0.166259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c-RC5GG2zNmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}